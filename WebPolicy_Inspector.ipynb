{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Clone the Sublist3r repository from GitHub\n",
        "!git clone https://github.com/aboul3la/Sublist3r.git\n",
        "\n",
        "# Step 2: Navigate to the Sublist3r directory and install required Python packages\n",
        "%cd Sublist3r\n",
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "id": "vumf0bEB82Ai"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Install additional dependencies for Selenium, NLP, and ChromeDriver\n",
        "!pip install selenium\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "\n",
        "# Update the system and install Chromium and ChromeDriver\n",
        "!apt-get update\n",
        "!apt-get install -y chromium-browser\n",
        "!apt-get install -y chromium-chromedriver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnyIxf6aUUL1",
        "outputId": "ae3a0753-337c-4b62-8bf9-4545ae571726"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.29.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.1.31)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Downloading selenium-4.29.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, outcome, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.29.0 trio-0.29.0 trio-websocket-0.12.2 wsproto-1.2.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [69.9 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,535 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,000 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,378 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,692 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,675 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,236 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,754 kB]\n",
            "Fetched 21.7 MB in 3s (6,427 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor libfuse3-3 liblzo2-2 snapd squashfs-tools systemd-hwe-hwdb udev\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor chromium-browser libfuse3-3 liblzo2-2 snapd squashfs-tools systemd-hwe-hwdb udev\n",
            "0 upgraded, 8 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 30.3 MB of archives.\n",
            "After this operation, 123 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.4 [598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblzo2-2 amd64 2.10-2build3 [53.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.12 [1,557 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.67.1+22.04 [27.8 MB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Fetched 30.3 MB in 1s (20.5 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 125044 files and directories currently installed.)\n",
            "Preparing to unpack .../0-apparmor_3.0.4-2ubuntu2.4_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Selecting previously unselected package liblzo2-2:amd64.\n",
            "Preparing to unpack .../1-liblzo2-2_2.10-2build3_amd64.deb ...\n",
            "Unpacking liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../2-squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.5-3build1) ...\n",
            "Selecting previously unselected package udev.\n",
            "Preparing to unpack .../3-udev_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package libfuse3-3:amd64.\n",
            "Preparing to unpack .../4-libfuse3-3_3.10.5-1build1_amd64.deb ...\n",
            "Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../5-snapd_2.67.1+22.04_amd64.deb ...\n",
            "Unpacking snapd (2.67.1+22.04) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Setting up squashfs-tools (1:4.5-3build1) ...\n",
            "Setting up udev (249.11-0ubuntu3.12) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Setting up snapd (2.67.1+22.04) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package chromium-browser.\n",
            "(Reading database ... 125481 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "Processing triggers for udev (249.11-0ubuntu3.12) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  chromium-chromedriver\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 2,308 B of archives.\n",
            "After this operation, 77.8 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n",
            "Fetched 2,308 B in 0s (13.5 kB/s)\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "(Reading database ... 125502 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the path of the installed ChromeDriver\n",
        "!which chromedriver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbjclh5eX_VR",
        "outputId": "ab81d2fc-9a8a-4825-c8d2-b8a6afcedc38"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/chromedriver\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import necessary libraries\n",
        "import textwrap\n",
        "import re\n",
        "import csv\n",
        "import os\n",
        "import torch\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from transformers import pipeline, BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# Define the Domain Analysis class, which extends Selenium's Chrome WebDriver\n",
        "class Domain_Analyse(webdriver.Chrome):\n",
        "    def __init__(self, driver_path, teardown=False):\n",
        "        self.driver_path = driver_path  # Path to ChromeDriver\n",
        "        self.teardown = teardown  # Whether to close the browser after use\n",
        "\n",
        "        # Set up Chrome options for headless mode (no GUI)\n",
        "        chrome_options = Options()\n",
        "        chrome_options.add_argument(\"--headless\")\n",
        "        chrome_options.add_argument(\"--disable-gpu\")\n",
        "        chrome_options.add_argument(\"--no-sandbox\")\n",
        "        os.environ[\"PATH\"] += os.pathsep + self.driver_path  # Add ChromeDriver to PATH\n",
        "\n",
        "        # Load NLP models for summarization and sentiment analysis\n",
        "        self.summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "        self.sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "        # Load BERT model and tokenizer for intent classification\n",
        "        self.model_name = \"bert-base-uncased\"\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(self.model_name)\n",
        "        self.model = BertForSequenceClassification.from_pretrained(self.model_name, num_labels=2)\n",
        "\n",
        "        # Initialize the Chrome WebDriver with the configured options\n",
        "        super().__init__(options=chrome_options)\n",
        "\n",
        "    # Method to enumerate subdomains using Sublist3r\n",
        "    def enumerate_subdomains(self, domain):\n",
        "        try:\n",
        "            print(f\"Enumerating subdomains for {domain}...\")\n",
        "            # Run Sublist3r to find subdomains and save the output to a file\n",
        "            !python sublist3r.py -d {domain_name} -o output.txt\n",
        "            subdomains = []\n",
        "            # Read the subdomains from the output file\n",
        "            with open('output.txt', 'r') as file:\n",
        "                subdomains = [line.strip() for line in file.readlines() if line.strip()]\n",
        "\n",
        "            print(f\"Found {len(subdomains)} subdomains for {domain}.\")\n",
        "            return subdomains\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while enumerating subdomains for {domain}: {e}\")\n",
        "            return []\n",
        "\n",
        "    # Method to find the URL of the terms and conditions page\n",
        "    def find_terms_url(self, url):\n",
        "        self.get(url)  # Navigate to the given URL\n",
        "        self.implicitly_wait(10)  # Wait for the page to load\n",
        "        # List of keywords to look for in the links\n",
        "        keywords = [\n",
        "            \"terms\", \"our-privacy-policy\", \"conditions\", \"privacy-policy\", \"policies-procedures\",\n",
        "            \"terms of service\", \"user agreement\", \"data protection\",\n",
        "            \"personal data\", \"data collection\", \"data usage\",\n",
        "            \"user consent\", \"data security\",\n",
        "            \"third-party sharing\", \"cookies policy\", \"policies-procedures\"\n",
        "        ]\n",
        "        # Find all links on the page\n",
        "        links = self.find_elements(By.TAG_NAME, \"a\")\n",
        "        # Check each link for the presence of keywords\n",
        "        for link in links:\n",
        "            href = link.get_attribute(\"href\")\n",
        "            if any(href.lower().endswith(f\"{keyword.lower()}/\") for keyword in keywords):\n",
        "                return href  # Return the URL if a match is found\n",
        "        return None  # Return None if no matching URL is found\n",
        "\n",
        "    # Method to scrape the terms and conditions text from a URL\n",
        "    def scrape_terms(self, url):\n",
        "        try:\n",
        "            # Find the terms and conditions URL\n",
        "            terms_url = self.find_terms_url(url)\n",
        "            if terms_url:\n",
        "                self.get(terms_url)  # Navigate to the terms URL\n",
        "                self.implicitly_wait(10)  # Wait for the page to load\n",
        "                # Extract the text from the page body\n",
        "                policy_text = self.find_element(By.TAG_NAME, \"body\").text\n",
        "                return policy_text, terms_url\n",
        "            else:\n",
        "                return \"Terms and Conditions not found.\", None\n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping terms: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    # Method to preprocess text by removing extra spaces and punctuation\n",
        "    def preprocess_text(self, text):\n",
        "        text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "        return text.strip()\n",
        "\n",
        "    # Method to classify the intent of the text using BERT\n",
        "    def classify_intent(self, text):\n",
        "        # Tokenize the text and truncate it to 512 tokens\n",
        "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        predicted_class = torch.argmax(logits, dim=1).item()  # Get the predicted class\n",
        "        return predicted_class  # 0 -> User Protection, 1 -> Data Exploitation\n",
        "\n",
        "    # Method to summarize the policy text using BART\n",
        "    def summarize_policy(self, text):\n",
        "        # Summarize the text, truncating to fit within the model's limit\n",
        "        summary = self.summarizer(text, max_length=512, min_length=10, do_sample=False)\n",
        "        return summary[0]['summary_text']\n",
        "\n",
        "    # Method to analyze the sentiment of the text\n",
        "    def analyze_sentiment(self, text):\n",
        "        result = self.sentiment_pipeline(text)  # Analyze sentiment\n",
        "        return result[0]  # Return the sentiment result\n",
        "\n",
        "    # Method to split text into chunks of 512 tokens for processing\n",
        "    def split_text_into_chunks(self, text, max_tokens=512):\n",
        "        tokens = self.tokenizer.encode(text, truncation=True, max_length=max_tokens)  # Tokenize the text\n",
        "        chunks = []\n",
        "        # Split the tokens into chunks\n",
        "        for i in range(0, len(tokens), max_tokens):\n",
        "            chunk = tokens[i:i + max_tokens]\n",
        "            chunks.append(self.tokenizer.decode(chunk))  # Decode tokens back to text\n",
        "        return chunks\n",
        "\n",
        "    # Method to analyze the policy text (sentiment, intent, and summary)\n",
        "    def analyze_policy(self, text):\n",
        "        preprocessed_text = self.preprocess_text(text)  # Preprocess the text\n",
        "\n",
        "        # Analyze sentiment\n",
        "        sentiment = self.analyze_sentiment(preprocessed_text)\n",
        "\n",
        "        # Split text into chunks if it exceeds the token limit\n",
        "        chunks = self.split_text_into_chunks(preprocessed_text)\n",
        "\n",
        "        # Classify intent for each chunk\n",
        "        intents = [self.classify_intent(chunk) for chunk in chunks]\n",
        "        intent = \"User Protection\" if intents.count(0) > intents.count(1) else \"Data Exploitation\"\n",
        "\n",
        "        # Summarize the policy\n",
        "        summary = self.summarize_policy(preprocessed_text)\n",
        "\n",
        "        return {\n",
        "            \"Sentiment\": sentiment,\n",
        "            \"Intent\": intent,\n",
        "            \"Summary\": summary,\n",
        "        }\n",
        "\n",
        "    # Method to clean up resources when exiting the context manager\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        if self.teardown:\n",
        "            self.quit()  # Close the browser\n",
        "\n",
        "# Helper function to print text in a wrapped format\n",
        "def print_wrapped_text(text, width=80):\n",
        "    print(\"\\n\".join(textwrap.wrap(text, width=width)))\n",
        "\n",
        "# Main function to execute the script\n",
        "if __name__ == \"__main__\":\n",
        "    driver_path = r\"/usr/bin/chromedriver\"  # Path to ChromeDriver\n",
        "    with open(r\"/content/top-1m.csv\", mode='r') as file:  # Open the CSV file containing domains\n",
        "        with Domain_Analyse(driver_path=r\"/usr/bin/chromedriver\") as DA:  # Initialize the Domain_Analyse class\n",
        "            csv_reader = csv.reader(file)  # Read the CSV file\n",
        "            for index, row in enumerate(csv_reader):\n",
        "                if index >= 1:  # Process only the first domain for demonstration\n",
        "                    break\n",
        "                domain_name = row[1]  # Get the domain name from the CSV\n",
        "                subdomain_list = DA.enumerate_subdomains(domain_name)  # Enumerate subdomains\n",
        "\n",
        "                # Print the list of subdomains\n",
        "                for ele in subdomain_list:\n",
        "                    print(ele)\n",
        "                print(\"\\n\")\n",
        "\n",
        "               # Analyze the terms and conditions for each subdomain\n",
        "                for subdomain in subdomain_list:\n",
        "                    # Assign the results of DA.scrape_terms to a single variable\n",
        "                    result = DA.scrape_terms(f\"https://{subdomain}\")\n",
        "                    # Check if the result contains two values before unpacking\n",
        "                    if result and len(result) == 2:\n",
        "                        policy_identified, terms_url = result\n",
        "                        print(f\"{terms_url} \\n\")\n",
        "                        print_wrapped_text(policy_identified)  # Print the policy text\n",
        "\n",
        "                        # Analyze the policy and print the results\n",
        "                        result = DA.analyze_policy(policy_identified)\n",
        "                        for key, value in result.items():\n",
        "                            print(f\"{key} -- {value}\")\n",
        "                    else:\n",
        "                        # Handle the case where DA.scrape_terms doesn't return two values\n",
        "                        print(f\"Could not find terms and conditions for {subdomain}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "783IQ7hSQG-d",
        "outputId": "7f5656ec-58db-4a22-cc2e-d9bbb205e717"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cuda:0\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating subdomains for termly.io...\n",
            "\u001b[91m\n",
            "                 ____        _     _ _     _   _____\n",
            "                / ___| _   _| |__ | (_)___| |_|___ / _ __\n",
            "                \\___ \\| | | | '_ \\| | / __| __| |_ \\| '__|\n",
            "                 ___) | |_| | |_) | | \\__ \\ |_ ___) | |\n",
            "                |____/ \\__,_|_.__/|_|_|___/\\__|____/|_|\u001b[0m\u001b[93m\n",
            "\n",
            "                # Coded By Ahmed Aboul-Ela - @aboul3la\n",
            "    \n",
            "\u001b[94m[-] Enumerating subdomains now for termly.io\u001b[0m\n",
            "\u001b[92m[-] Searching now in Baidu..\u001b[0m\n",
            "\u001b[92m[-] Searching now in Yahoo..\u001b[0m\n",
            "\u001b[92m[-] Searching now in Google..\u001b[0m\n",
            "\u001b[92m[-] Searching now in Bing..\u001b[0m\n",
            "\u001b[92m[-] Searching now in Ask..\u001b[0m\n",
            "\u001b[92m[-] Searching now in Netcraft..\u001b[0m\n",
            "\u001b[92m[-] Searching now in DNSdumpster..\u001b[0m\n",
            "\u001b[92m[-] Searching now in Virustotal..\u001b[0m\n",
            "\u001b[92m[-] Searching now in ThreatCrowd..\u001b[0m\n",
            "\u001b[92m[-] Searching now in SSL Certificates..\u001b[0m\n",
            "\u001b[92m[-] Searching now in PassiveDNS..\u001b[0m\n",
            "Process DNSdumpster-8:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/content/Sublist3r/sublist3r.py\", line 268, in run\n",
            "    domain_list = self.enumerate()\n",
            "                  ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Sublist3r/sublist3r.py\", line 647, in enumerate\n",
            "    token = self.get_csrftoken(resp)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Sublist3r/sublist3r.py\", line 641, in get_csrftoken\n",
            "    token = csrf_regex.findall(resp)[0]\n",
            "            ~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
            "IndexError: list index out of range\n",
            "\u001b[91m[!] Error: Virustotal probably now is blocking our requests\u001b[0m\n",
            "\u001b[91m[!] Error: Google probably now is blocking our requests\u001b[0m\n",
            "\u001b[91m[~] Finished now the Google Enumeration ...\u001b[0m\n",
            "\u001b[93m[-] Saving results to file: \u001b[0m\u001b[91moutput.txt\u001b[0m\n",
            "\u001b[93m[-] Total Unique Subdomains Found: 12\u001b[0m\n",
            "\u001b[92mwww.termly.io\u001b[0m\n",
            "\u001b[92mapi.termly.io\u001b[0m\n",
            "\u001b[92mus.consent.api.termly.io\u001b[0m\n",
            "\u001b[92mapp.termly.io\u001b[0m\n",
            "\u001b[92mwww.app.termly.io\u001b[0m\n",
            "\u001b[92mdoc.termly.io\u001b[0m\n",
            "\u001b[92mdocs.termly.io\u001b[0m\n",
            "\u001b[92mhelp.termly.io\u001b[0m\n",
            "\u001b[92mpredesign.termly.io\u001b[0m\n",
            "\u001b[92mstaging.termly.io\u001b[0m\n",
            "\u001b[92mstatus.termly.io\u001b[0m\n",
            "\u001b[92msupport.termly.io\u001b[0m\n",
            "Found 12 subdomains for termly.io.\n",
            "www.termly.io\n",
            "api.termly.io\n",
            "us.consent.api.termly.io\n",
            "app.termly.io\n",
            "www.app.termly.io\n",
            "doc.termly.io\n",
            "docs.termly.io\n",
            "help.termly.io\n",
            "predesign.termly.io\n",
            "staging.termly.io\n",
            "status.termly.io\n",
            "support.termly.io\n",
            "\n",
            "\n",
            "Error scraping terms: 'NoneType' object has no attribute 'lower'\n",
            "Could not find terms and conditions for www.termly.io\n",
            "None \n",
            "\n",
            "Terms and Conditions not found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 512, but your input_length is only 7. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment -- {'label': 'NEGATIVE', 'score': 0.9978312849998474}\n",
            "Intent -- User Protection\n",
            "Summary -- CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery. Please submit your best shots for next week. Visit CNN.com/Travel next Wednesday for a new gallery of snapshots.\n",
            "Error scraping terms: 'NoneType' object has no attribute 'lower'\n",
            "Could not find terms and conditions for us.consent.api.termly.io\n",
            "https://termly.io/our-privacy-policy/ \n",
            "\n",
            "Open Navigation menu   Home  ›  Termly’s Privacy Notice Termly’s Privacy Notice\n",
            "Company About Us Careers Updates and Press Our Privacy Center Our Privacy Policy\n",
            "Our Terms of Use Our Disclaimer Our Cookie Policy Our Sub-Processors Limit the\n",
            "Use of My Sensitive Personal Information Do Not Sell or Share My Information\n",
            "Products Privacy Policy Generator Terms and Conditions Generator EULA Generator\n",
            "Impressum Generator Refund & Return Policy Shipping Policy Generator Disclaimer\n",
            "Generator Consent Management Platform Cookie Consent Cookie Banner Cookie Policy\n",
            "Generator Cookie Scanner Support Help and Support FAQs Contact Us Pricing\n",
            "Partner with Us Resources Cookie Preferences Legal Dictionary Security FAQ Our\n",
            "Brands WP Rocket Imagify Rank Math RocketCDN BackWPup one.com Disclaimer: Termly\n",
            "Inc is not a lawyer or a law firm and does not engage in the practice of law or\n",
            "provide legal advice or legal representation. All information, software,\n",
            "services, and comments provided on the site are for informational and self-help\n",
            "purposes only and are not intended to be a substitute for professional legal\n",
            "advice. Use of this site is subject to our Terms of Use. Copyright Termly 2025\n",
            "EN FR ES DE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 512, but your input_length is only 211. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=105)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment -- {'label': 'NEGATIVE', 'score': 0.9917758703231812}\n",
            "Intent -- User Protection\n",
            "Summary -- Termlys is not a lawyer or a law firm and does not engage in the practice of law or provide legal advice or legal representation. All information software services and comments provided on the site are for informational and selfhelp purposes only and are not intended to be a substitute for professional legal advice. Use of this site is subject to our Terms of Use.\n",
            "Error scraping terms: Message: unknown error: net::ERR_NAME_NOT_RESOLVED\n",
            "  (Session info: chrome=134.0.6998.88)\n",
            "Stacktrace:\n",
            "#0 0x57ecc625aa1a <unknown>\n",
            "#1 0x57ecc5d12390 <unknown>\n",
            "#2 0x57ecc5d09518 <unknown>\n",
            "#3 0x57ecc5cf9a39 <unknown>\n",
            "#4 0x57ecc5cfb73d <unknown>\n",
            "#5 0x57ecc5cf9dce <unknown>\n",
            "#6 0x57ecc5cf9775 <unknown>\n",
            "#7 0x57ecc5cf9449 <unknown>\n",
            "#8 0x57ecc5cf7159 <unknown>\n",
            "#9 0x57ecc5cf7a2a <unknown>\n",
            "#10 0x57ecc5d15829 <unknown>\n",
            "#11 0x57ecc5db0d85 <unknown>\n",
            "#12 0x57ecc5d89bd2 <unknown>\n",
            "#13 0x57ecc5db007b <unknown>\n",
            "#14 0x57ecc5d899a3 <unknown>\n",
            "#15 0x57ecc5d5560e <unknown>\n",
            "#16 0x57ecc5d56dd1 <unknown>\n",
            "#17 0x57ecc6220ddb <unknown>\n",
            "#18 0x57ecc6224cbc <unknown>\n",
            "#19 0x57ecc6208392 <unknown>\n",
            "#20 0x57ecc6225834 <unknown>\n",
            "#21 0x57ecc61ec1ef <unknown>\n",
            "#22 0x57ecc6249038 <unknown>\n",
            "#23 0x57ecc6249216 <unknown>\n",
            "#24 0x57ecc6259896 <unknown>\n",
            "#25 0x78210ae9fac3 <unknown>\n",
            "\n",
            "Could not find terms and conditions for www.app.termly.io\n",
            "Error scraping terms: Message: unknown error: net::ERR_NAME_NOT_RESOLVED\n",
            "  (Session info: chrome=134.0.6998.88)\n",
            "Stacktrace:\n",
            "#0 0x57ecc625aa1a <unknown>\n",
            "#1 0x57ecc5d12390 <unknown>\n",
            "#2 0x57ecc5d09518 <unknown>\n",
            "#3 0x57ecc5cf9a39 <unknown>\n",
            "#4 0x57ecc5cfb73d <unknown>\n",
            "#5 0x57ecc5cf9dce <unknown>\n",
            "#6 0x57ecc5cf9775 <unknown>\n",
            "#7 0x57ecc5cf9449 <unknown>\n",
            "#8 0x57ecc5cf7159 <unknown>\n",
            "#9 0x57ecc5cf7a2a <unknown>\n",
            "#10 0x57ecc5d15829 <unknown>\n",
            "#11 0x57ecc5db0d85 <unknown>\n",
            "#12 0x57ecc5d89bd2 <unknown>\n",
            "#13 0x57ecc5db007b <unknown>\n",
            "#14 0x57ecc5d899a3 <unknown>\n",
            "#15 0x57ecc5d5560e <unknown>\n",
            "#16 0x57ecc5d56dd1 <unknown>\n",
            "#17 0x57ecc6220ddb <unknown>\n",
            "#18 0x57ecc6224cbc <unknown>\n",
            "#19 0x57ecc6208392 <unknown>\n",
            "#20 0x57ecc6225834 <unknown>\n",
            "#21 0x57ecc61ec1ef <unknown>\n",
            "#22 0x57ecc6249038 <unknown>\n",
            "#23 0x57ecc6249216 <unknown>\n",
            "#24 0x57ecc6259896 <unknown>\n",
            "#25 0x78210ae9fac3 <unknown>\n",
            "\n",
            "Could not find terms and conditions for doc.termly.io\n",
            "None \n",
            "\n",
            "Terms and Conditions not found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 512, but your input_length is only 7. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment -- {'label': 'NEGATIVE', 'score': 0.9978312849998474}\n",
            "Intent -- User Protection\n",
            "Summary -- CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery. Please submit your best shots for next week. Visit CNN.com/Travel next Wednesday for a new gallery of snapshots.\n",
            "None \n",
            "\n",
            "Terms and Conditions not found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 512, but your input_length is only 7. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment -- {'label': 'NEGATIVE', 'score': 0.9978312849998474}\n",
            "Intent -- User Protection\n",
            "Summary -- CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery. Please submit your best shots for next week. Visit CNN.com/Travel next Wednesday for a new gallery of snapshots.\n",
            "https://termlyv3dev.wpengine.com/our-privacy-policy/ \n",
            "\n",
            "Open Navigation menu   Home  ›  Termly’s Privacy Notice Termly’s Privacy Notice\n",
            "Company About Us Careers Updates and Press Our Privacy Center Our Privacy Policy\n",
            "Our Terms of Use Our Disclaimer Our Cookie Policy Our Sub-Processors Limit the\n",
            "Use of My Sensitive Personal Information Do Not Sell or Share My Information\n",
            "Products Privacy Policy Generator Terms and Conditions Generator EULA Generator\n",
            "Refund & Return Policy Shipping Policy Generator Disclaimer Generator Consent\n",
            "Management Platform Cookie Consent Cookie Banner Cookie Policy Generator Cookie\n",
            "Scanner Support Help and Support FAQs Contact Us Pricing Partner with Us\n",
            "Resources Cookie Preferences Legal Dictionary Security FAQ Our Brands WP Rocket\n",
            "Imagify Rank Math RocketCDN BackWPup one.com Disclaimer: Termly Inc is not a\n",
            "lawyer or a law firm and does not engage in the practice of law or provide legal\n",
            "advice or legal representation. All information, software, services, and\n",
            "comments provided on the site are for informational and self-help purposes only\n",
            "and are not intended to be a substitute for professional legal advice. Use of\n",
            "this site is subject to our Terms of Use. Copyright Termly 2023 EN FR ES DE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 512, but your input_length is only 208. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=104)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment -- {'label': 'NEGATIVE', 'score': 0.9896798133850098}\n",
            "Intent -- User Protection\n",
            "Summary -- Termlys is not a lawyer or a law firm and does not engage in the practice of law or provide legal advice or legal representation. All information software services and comments provided on the site are for informational and selfhelp purposes only and are not intended to be a substitute for professional legal advice. Use of this site is subject to our Terms of Use.\n",
            "https://staging.termly.io/our-privacy-policy/ \n",
            "\n",
            "We use essential cookies to make our site work. With your consent, we may also\n",
            "use non-essential cookies to improve user experience, personalize content,\n",
            "customize advertisements, and analyze website traffic. For these reasons, we may\n",
            "share your site usage data with our social media, advertising, and analytics\n",
            "partners. By clicking ”Accept,” you agree to our website's cookie use as\n",
            "described in our Cookie Policy. You can change your cookie settings at any time\n",
            "by clicking “Preferences.” Preferences Decline Accept Open Navigation menu\n",
            "Home  ›  Termly’s Privacy Notice Termly’s Privacy Notice Company About Us\n",
            "Careers Updates and Press Our Privacy Center Our Privacy Policy Our Terms of Use\n",
            "Our Disclaimer Our Cookie Policy Our Sub-Processors Limit the Use of My\n",
            "Sensitive Personal Information Do Not Sell or Share My Information Products\n",
            "Privacy Policy Generator Terms and Conditions Generator EULA Generator Impressum\n",
            "Generator Refund & Return Policy Shipping Policy Generator Disclaimer Generator\n",
            "Consent Management Platform Cookie Consent Cookie Banner Cookie Policy Generator\n",
            "Cookie Scanner Support Help and Support FAQs Contact Us Pricing Partner with Us\n",
            "Resources Cookie Preferences Legal Dictionary Security FAQ Our Brands WP Rocket\n",
            "Imagify Rank Math RocketCDN BackWPup one.com Disclaimer: Termly Inc is not a\n",
            "lawyer or a law firm and does not engage in the practice of law or provide legal\n",
            "advice or legal representation. All information, software, services, and\n",
            "comments provided on the site are for informational and self-help purposes only\n",
            "and are not intended to be a substitute for professional legal advice. Use of\n",
            "this site is subject to our Terms of Use. Copyright Termly 2024 EN FR ES DE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 512, but your input_length is only 293. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=146)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment -- {'label': 'NEGATIVE', 'score': 0.9959775805473328}\n",
            "Intent -- Data Exploitation\n",
            "Summary -- We use essential cookies to make our site work With your consent we may also use nonessential cookies to improve user experience personalize content customize advertisements and analyze website traffic. For these reasons we may share your site usage data with our social media advertising and analytics partners By clicking Accept you agree to our websites cookie use as described in our Cookie Policy.\n",
            "None \n",
            "\n",
            "Terms and Conditions not found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 512, but your input_length is only 7. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment -- {'label': 'NEGATIVE', 'score': 0.9978312849998474}\n",
            "Intent -- User Protection\n",
            "Summary -- CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery. Please submit your best shots for next week. Visit CNN.com/Travel next Wednesday for a new gallery of snapshots.\n",
            "None \n",
            "\n",
            "Terms and Conditions not found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 512, but your input_length is only 7. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment -- {'label': 'NEGATIVE', 'score': 0.9978312849998474}\n",
            "Intent -- User Protection\n",
            "Summary -- CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery. Please submit your best shots for next week. Visit CNN.com/Travel next Wednesday for a new gallery of snapshots.\n"
          ]
        }
      ]
    }
  ]
}